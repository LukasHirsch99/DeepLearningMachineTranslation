{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3cb4c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "ds = load_dataset(\"wmt/wmt14\", \"de-en\", cache_dir=\"./data/wmt14\")\n",
    "\n",
    "vocab_size = 30_000\n",
    "vocab_path = \"./data/bpe_tokenizer.json\"\n",
    "\n",
    "training_samples = 10_000\n",
    "batch_size = 64\n",
    "dataset_max_sample_len = 100\n",
    "\n",
    "# bpe_v3_ep12\n",
    "d_model=256\n",
    "nhead=8\n",
    "num_encoder_layers=4\n",
    "num_decoder_layers=4\n",
    "dim_feedforward=1024\n",
    "dropout=0.1\n",
    "max_len=150\n",
    "\n",
    "# big_3.8770loss\n",
    "# d_model=512\n",
    "# nhead=8\n",
    "# num_encoder_layers=2\n",
    "# num_decoder_layers=2\n",
    "# dim_feedforward=2048\n",
    "# dropout=0.1\n",
    "# max_len=150\n",
    "\n",
    "# training\n",
    "num_epochs = 100\n",
    "warmup_steps = 2000\n",
    "eval_iters = 30\n",
    "patience = 30\n",
    "\n",
    "label_smoothing = 0.1\n",
    "\n",
    "# optimizer\n",
    "start_lr = 3e-4\n",
    "betas = (0.9, 0.98)\n",
    "epsilon = 1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57fa5836",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer as HFTokenizer, decoders\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from tokenizers.pre_tokenizers import Metaspace\n",
    "from tokenization_vocab import HFTokenizerWrapper, Tokenizer\n",
    "from pathlib import Path\n",
    "\n",
    "bpe_tokenizer = HFTokenizer(BPE(unk_token=Tokenizer.UNK_TOKEN))\n",
    "trainer = BpeTrainer(\n",
    "    special_tokens=[Tokenizer.PAD_TOKEN, Tokenizer.SOS_TOKEN, Tokenizer.EOS_TOKEN, Tokenizer.UNK_TOKEN],\n",
    "    vocab_size=vocab_size,\n",
    "    show_progress=True\n",
    ")\n",
    "\n",
    "bpe_tokenizer.pre_tokenizer = Metaspace()\n",
    "bpe_tokenizer.decoder = decoders.Metaspace()\n",
    "\n",
    "pretrained = True  # Set to True if you want to load a previously saved tokenizer\n",
    "\n",
    "Path(vocab_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if Path(vocab_path).is_file():\n",
    "    pretrained = True\n",
    "\n",
    "if pretrained:\n",
    "    bpe_tokenizer = HFTokenizer.from_file(vocab_path)\n",
    "else:\n",
    "    bpe_tokenizer.train(\n",
    "        [\n",
    "            './datasets/wmt14_translate_de-en_test.csv',\n",
    "            './datasets/wmt14_translate_de-en_train.csv',\n",
    "            './datasets/wmt14_translate_de-en_validation.csv',\n",
    "        ],\n",
    "        trainer=trainer\n",
    "    )\n",
    "\n",
    "    bpe_tokenizer.save(vocab_path)\n",
    "\n",
    "\n",
    "tokenizer = HFTokenizerWrapper(bpe_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a32cb9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing dataset...\n",
      "Preprocessed 9932 sentence pairs\n",
      "Skipped 68 pairs (too long)\n",
      "Preprocessing dataset...\n",
      "Preprocessed 3002 sentence pairs\n",
      "Skipped 1 pairs (too long)\n"
     ]
    }
   ],
   "source": [
    "from parallel_corpus import TranslationDataset, DataLoaderFactory\n",
    "from tokenization_vocab import HFTokenizerWrapper\n",
    "\n",
    "train_pairs = [(s['de'], s['en']) for s in ds['train'][:training_samples]['translation']]\n",
    "test_pairs = [(s['de'], s['en']) for s in ds['test']['translation']]\n",
    "\n",
    "sample_sentences_de = [s[0] for s in train_pairs]\n",
    "sample_sentences_en = [s[1] for s in train_pairs]\n",
    "\n",
    "tokenizer = HFTokenizerWrapper(bpe_tokenizer)\n",
    "\n",
    "train_sents, test_sents = train_pairs, test_pairs\n",
    "\n",
    "train_ds = TranslationDataset(\n",
    "    source_sentences=[s[0] for s in train_sents],\n",
    "    target_sentences=[s[1] for s in train_sents],\n",
    "    source_tokenizer=tokenizer,\n",
    "    target_tokenizer=tokenizer,\n",
    "    max_length=dataset_max_sample_len\n",
    ")\n",
    "\n",
    "test_ds = TranslationDataset(\n",
    "    source_sentences=[s[0] for s in test_sents],\n",
    "    target_sentences=[s[1] for s in test_sents],\n",
    "    source_tokenizer=tokenizer,\n",
    "    target_tokenizer=tokenizer,\n",
    "    max_length=dataset_max_sample_len\n",
    ")\n",
    "\n",
    "train_loader = DataLoaderFactory.create_dataloader(\n",
    "    dataset=train_ds,\n",
    "    batch_size=batch_size,\n",
    "    pad_idx=tokenizer.pad_idx,\n",
    "    shuffle=True  # IMPORTANT: Shuffle data each epoch for better training\n",
    ")\n",
    "\n",
    "test_loader = DataLoaderFactory.create_dataloader(\n",
    "    dataset=test_ds,\n",
    "    batch_size=batch_size,\n",
    "    pad_idx=tokenizer.pad_idx,\n",
    "    shuffle=True  # IMPORTANT: Shuffle data each epoch for better training\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4ab7bed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized!\n",
      "Total parameters: 30,431,536\n"
     ]
    }
   ],
   "source": [
    "# Import the TranslationTransformer\n",
    "from translation_transformer import TranslationTransformer, TranslationTransformerPytorch\n",
    "\n",
    "# Initialize the model with larger max_len to handle max_length + special tokens\n",
    "model = TranslationTransformer(\n",
    "    src_vocab_size=len(tokenizer),\n",
    "    tgt_vocab_size=len(tokenizer),\n",
    "    d_model=d_model,\n",
    "    nhead=nhead,\n",
    "    num_encoder_layers=num_encoder_layers,\n",
    "    num_decoder_layers=num_decoder_layers,\n",
    "    dim_feedforward=dim_feedforward,\n",
    "    dropout=dropout,\n",
    "    max_len=max_len,\n",
    "    padding_idx=tokenizer.pad_idx\n",
    ")\n",
    "\n",
    "print(f\"Model initialized!\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8a77102a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TranslationTransformer(\n",
       "  (src_embedding): WordEmbedding(\n",
       "    (embedding): Embedding(30000, 256, padding_idx=0)\n",
       "  )\n",
       "  (tgt_embedding): WordEmbedding(\n",
       "    (embedding): Embedding(30000, 256, padding_idx=0)\n",
       "  )\n",
       "  (positional_encoding): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder_layers): ModuleList(\n",
       "    (0-3): 4 x TransformerEncoderLayer(\n",
       "      (self_attn): MultiHeadAttention(\n",
       "        (qkv_proj): Linear(in_features=256, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "      )\n",
       "      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (ff): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "        (3): Linear(in_features=1024, out_features=256, bias=True)\n",
       "      )\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (dropout2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (decoder_layers): ModuleList(\n",
       "    (0-3): 4 x TransformerDecoderLayer(\n",
       "      (self_attn): MultiHeadAttention(\n",
       "        (qkv_proj): Linear(in_features=256, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "      )\n",
       "      (cross_attn): MultiHeadAttention(\n",
       "        (qkv_proj): Linear(in_features=256, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "      )\n",
       "      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (ff): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "        (3): Linear(in_features=1024, out_features=256, bias=True)\n",
       "      )\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      (dropout3): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (encoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "  (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "  (fc_out): Linear(in_features=256, out_features=30000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = torch.load(\"./models/bpe_v3_ep12_3.8523loss.pt\", map_location=DEVICE)['model_state_dict']\n",
    "new_state_dict = {\n",
    "    k.replace(\"_orig_mod.\", \"\"): v\n",
    "    for k, v in state_dict.items()\n",
    "}\n",
    "model.load_state_dict(new_state_dict)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b1811902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Model moved to mps\n"
     ]
    }
   ],
   "source": [
    "# Apply PyTorch optimizations\n",
    "import torch\n",
    "\n",
    "# 1. Enable TF32 for faster matmul on Ampere+ GPUs (A100, RTX 3090, etc.)\n",
    "# This provides ~2x speedup for matrix multiplications with minimal accuracy loss\n",
    "torch.set_float32_matmul_precision('high')  # Options: 'highest', 'high', 'medium'\n",
    "\n",
    "# 2. For MPS (Apple Silicon), ensure we're using optimal settings\n",
    "if DEVICE.type == \"mps\":\n",
    "    # MPS backend is already optimized, but we can ensure memory efficiency\n",
    "    torch.mps.empty_cache()  # Clear any cached memory\n",
    "elif DEVICE.type == \"cuda\":\n",
    "    # Enable TF32 for cuDNN convolutions as well\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "else:\n",
    "    print(\"✓ Running on CPU (no GPU optimizations)\")\n",
    "\n",
    "# 3. Don't compile for now while debugging mask issues\n",
    "# Once stable, uncomment below for 2-10x speedup\n",
    "model_compiled = model\n",
    "# model_compiled = torch.compile(model, mode='default')  # Options: 'default', 'reduce-overhead', 'max-autotune'\n",
    "\n",
    "# Move model to device (GPU if available)\n",
    "model = model.to(DEVICE)\n",
    "model.train()\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "print(f\"Model moved to {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e887e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Model moved to mps\n",
      "Starting training for 100 epochs...\n",
      "Total batches per epoch: 140\n",
      "Dataset size: 8938 samples\n",
      "Learning rate: 2.9999999999999997e-05 (with warmup and decay)\n",
      "============================================================\n",
      "\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel moved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDEVICE\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Training\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m train_losses, best_loss = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_compiled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset_size\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwarmup_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwarmup_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_iters\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_iters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpatience\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/TU-Wien/3. Semester/DeepLearning/project/train.py:187\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model, dataloader, dataset_size, train_loader, test_loader, criterion, optimizer, device, num_epochs, warmup_steps, eval_iters, patience)\u001b[39m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m epoch == \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mmodel_compiled\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mdir\u001b[39m():\n\u001b[32m    186\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m  ⏳ Compiling model on first batch (this will take extra time)...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m avg_loss = \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    189\u001b[39m current_lr = scheduler.get_last_lr()[\u001b[32m0\u001b[39m]\n\u001b[32m    191\u001b[39m epoch_time = time.time() - start_time\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/TU-Wien/3. Semester/DeepLearning/project/train.py:82\u001b[39m, in \u001b[36mtrain_epoch\u001b[39m\u001b[34m(model, dataloader, test_loader, criterion, optimizer, device, scheduler)\u001b[39m\n\u001b[32m     79\u001b[39m loss = criterion(output, tgt_output)\n\u001b[32m     81\u001b[39m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[38;5;66;03m# Gradient clipping to prevent exploding gradients\u001b[39;00m\n\u001b[32m     85\u001b[39m torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=\u001b[32m1.0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.13/site-packages/torch/_tensor.py:625\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    617\u001b[39m         Tensor.backward,\n\u001b[32m    618\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    623\u001b[39m         inputs=inputs,\n\u001b[32m    624\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.13/site-packages/torch/autograd/__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.13/site-packages/torch/autograd/graph.py:841\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    840\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    842\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    844\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from train import train\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_idx, label_smoothing=label_smoothing)\n",
    "optimizer = optim.Adam(model.parameters(), lr=start_lr, betas=betas, eps=epsilon)\n",
    "\n",
    "# Training\n",
    "train_losses, best_loss = train(\n",
    "    model=model_compiled,\n",
    "    dataloader=train_loader,\n",
    "    dataset_size=len(train_ds),\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    device=DEVICE,\n",
    "    num_epochs=num_epochs,\n",
    "    warmup_steps=warmup_steps,\n",
    "    eval_iters=eval_iters,\n",
    "    patience=patience\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f7417f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training progress\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(train_losses) + 1), train_losses, marker='o', linewidth=2, markersize=6)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Training Loss', fontsize=12)\n",
    "plt.title('Training Loss Over Time', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nTraining Summary:\")\n",
    "print(f\"  Initial Loss: {train_losses[0]:.4f}\")\n",
    "print(f\"  Final Loss: {train_losses[-1]:.4f}\")\n",
    "print(f\"  Best Loss: {best_loss:.4f}\")\n",
    "print(f\"  Improvement: {((train_losses[0] - train_losses[-1]) / train_losses[0] * 100):.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1b52ba02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tokens: ['▁Jahres', 'zeiten', 'bed', 'ingt', '▁laufen', '▁seit', '▁September', '▁auch', '▁wieder', '▁Stellen', 'angebote', '▁für', '▁Personal', '▁im', '▁Hotel', '-', '▁und', '▁Gast', 'stätten', 'ge', 'werbe', '▁ein', '.']\n",
      "Input tensor shape: torch.Size([1, 24])\n",
      "Input indices: [7466, 12056, 5937, 8964, 19415, 5667, 7363, 4078, 5045, 12539, 23277, 3944, 9891, 3928, 4419, 19, 3830, 10712, 24150, 3813, 29336, 3840, 20, 2]\n",
      "Generated 32 tokens\n",
      "Predicted indices: [1, 4642, 3790, 4950, 3815, 7363, 4283, 4111, 4328, 3774, 5232, 3815, 4645, 4439, 4040, 4328, 3796, 6784, 3815, 18472, 3796, 3790, 6029, 3815, 3790, 5212, 3822, 10026, 4317, 6449, 20, 2]\n",
      "Input tokens: ['▁Im', '▁Anschluss', '▁an', '▁Ch', 'ens', '▁Entsch', 'uld', 'igung', '▁veröffentlich', 'te', '▁der', '▁Neue', '▁Express', '▁eine', '▁Entsch', 'uld', 'igung', '▁auf', '▁der', '▁Tit', 'els', 'eite', '▁und', '▁erklär', 'te,', '▁man', '▁habe', '▁es', '▁vers', 'äum', 't,', '▁die', '▁Berichte', '▁korrekt', '▁zu', '▁überprüfen', '.']\n",
      "Input tensor shape: torch.Size([1, 38])\n",
      "Input indices: [5282, 17807, 3804, 4402, 4051, 13238, 4052, 4981, 10097, 3801, 3829, 21111, 15344, 3991, 13238, 4052, 4981, 3942, 3829, 14924, 4952, 6280, 3830, 7686, 4575, 4149, 5327, 4045, 4741, 8358, 3974, 3827, 13383, 20667, 3901, 20757, 20, 2]\n",
      "Generated 30 tokens\n",
      "Predicted indices: [1, 3985, 3790, 7509, 3815, 4402, 14420, 12832, 11276, 3774, 4398, 9249, 5302, 3887, 12832, 3822, 3950, 4076, 4939, 3823, 8196, 3790, 10167, 4071, 4040, 4328, 14453, 25754, 20, 2]\n",
      "Input tokens: ['▁Zu', '▁hören', '▁waren', '▁überwiegend', '▁die', '▁Gäste', 'f', 'ans', '▁mit', '▁ihren', '▁Ges', 'ängen', '.']\n",
      "Input tensor shape: torch.Size([1, 14])\n",
      "Input indices: [5387, 18241, 6820, 28468, 3827, 7089, 76, 4614, 3952, 5757, 4907, 11913, 20, 2]\n",
      "Generated 12 tokens\n",
      "Predicted indices: [1, 25837, 3815, 4737, 4647, 4723, 19346, 3823, 4321, 18766, 7464, 2]\n",
      "Input tokens: ['▁He', 'ch', 'ingen', ':', '▁Messe', '▁gibt', '▁Antwort', '▁auf', '▁Hochzeit', 's', '-F', 'ragen']\n",
      "Input tensor shape: torch.Size([1, 13])\n",
      "Input indices: [5115, 3777, 8440, 32, 13508, 4926, 8506, 3942, 24776, 89, 5570, 9312, 2]\n",
      "Generated 19 tokens\n",
      "Predicted indices: [1, 5115, 3786, 12760, 32, 4284, 90, 3838, 3774, 5636, 3815, 3790, 19772, 3790, 23233, 6540, 17669, 20, 2]\n",
      "Input tokens: ['▁Ze', 'ugen', '▁sah', 'en', '▁zwei', '▁Menschen', '▁in', '▁dem', '▁Auto', '▁sitz', 'en.']\n",
      "Input tensor shape: torch.Size([1, 12])\n",
      "Input indices: [9297, 6223, 17386, 3771, 5383, 4850, 3796, 3997, 10987, 23753, 7414, 2]\n",
      "Generated 12 tokens\n",
      "Predicted indices: [1, 3890, 4165, 4283, 4647, 4906, 4645, 3796, 3790, 5044, 20, 2]\n",
      "Input tokens: ['▁Als', '▁seine', '▁bet', 'ag', 'te', '▁Mutter', '▁star', 'b', ',', '▁sch', 'mie', 'dete', '▁ein', '▁Mann', '▁aus', '▁Wolf', 's', 'burg', '▁einen', '▁Plan', '.']\n",
      "Input tensor shape: torch.Size([1, 22])\n",
      "Input indices: [8418, 5155, 4379, 4031, 3801, 14299, 6081, 72, 18, 4098, 25826, 11592, 3840, 10496, 4048, 17060, 89, 6140, 4238, 7825, 20, 2]\n",
      "Generated 25 tokens\n",
      "Predicted indices: [1, 20536, 4729, 3797, 3863, 4142, 16759, 18, 4146, 7446, 3785, 7934, 3774, 4149, 3815, 3785, 13105, 3826, 3774, 6840, 3887, 3774, 6840, 20, 2]\n",
      "Input tokens: ['▁Und', '▁manchmal', '▁will', '▁man', '▁einfach', '▁auch', '▁nur', '▁seine', '▁Ruhe', \"',\", '▁glaub', 't', '▁sie', '.']\n",
      "Input tensor shape: torch.Size([1, 15])\n",
      "Input indices: [7776, 14347, 4056, 4149, 5521, 4078, 4361, 5155, 14107, 10920, 6283, 90, 4189, 20, 2]\n",
      "Generated 19 tokens\n",
      "Predicted indices: [1, 7418, 11110, 4053, 4056, 7604, 5213, 3908, 3950, 3838, 8589, 3908, 3950, 3838, 3774, 5426, 4938, 20, 2]\n",
      "Input tokens: ['▁Dieser', '▁Fall', '▁sollte', '▁Krim', 'ine', 'llen', '▁eine', '▁War', 'nung', '▁sein', '▁und', '▁zeigt,', '▁dass', '▁sich', '▁keiner', '▁dem', '▁Arm', '▁des', '▁Gesetzes', '▁ent', 'ziehen', '▁kann.']\n",
      "Input tensor shape: torch.Size([1, 23])\n",
      "Input indices: [10311, 6023, 5552, 15186, 4142, 4410, 3991, 6304, 5120, 4160, 3830, 16251, 4042, 4025, 10137, 3997, 15653, 3948, 17512, 4105, 12489, 23240, 2]\n",
      "Generated 26 tokens\n",
      "Predicted indices: [1, 7602, 6029, 3815, 9918, 27651, 4376, 3836, 3774, 22283, 16965, 3822, 9842, 3908, 4477, 4372, 4148, 28830, 3790, 6348, 8396, 3815, 3790, 5975, 20, 2]\n",
      "Input tokens: ['▁Der', '▁Einzel', 'handels', 'ausschuss', '▁der', '▁I', 'H', 'K', '▁Frankfurt', '▁hält', '▁das', '▁\"', 'für', '▁keine', '▁gute', '▁Idee', '\"', '.']\n",
      "Input tensor shape: torch.Size([1, 19])\n",
      "Input indices: [4899, 8934, 14745, 9693, 3829, 3862, 46, 49, 12895, 14146, 3899, 3825, 11435, 4888, 7262, 13205, 8, 20, 2]\n",
      "Generated 16 tokens\n",
      "Predicted indices: [1, 4610, 7192, 5968, 3900, 21327, 11216, 21127, 3908, 4283, 3838, 4477, 4889, 8659, 20, 2]\n",
      "Input tokens: ['▁Oder', '▁wir', '▁können', '▁unsere', '▁eigenen', '▁wirtschaftlichen', '▁Interessen', '▁verteidigen', '▁–', '▁wozu', '▁auch', '▁gehört,', '▁Berlin', '▁und', '▁Brüssel', '▁zu', '▁sagen,', '▁was', '▁sie', '▁sich', '▁wo', '▁hin', 'ste', 'cken', '▁können.']\n",
      "Input tensor shape: torch.Size([1, 26])\n",
      "Input indices: [24914, 3933, 4356, 4879, 6612, 8595, 8897, 22807, 4330, 29257, 4078, 19179, 7011, 3830, 13619, 3901, 7098, 4076, 4189, 4025, 4801, 4573, 4021, 6779, 18049, 2]\n",
      "Generated 20 tokens\n",
      "Predicted indices: [1, 4736, 3943, 4148, 13980, 4170, 5069, 5243, 8827, 5907, 7011, 3822, 16043, 3900, 4671, 4461, 4148, 4211, 20, 2]\n",
      "Input tokens: ['▁Beim', '▁Thema', '▁Verkehr', ',', '▁das', '▁an', '▁diesem', '▁Freitag', '▁nicht', '▁auf', '▁der', '▁Tag', 'ungs', 'ordnung', '▁steht,', '▁unter', 'm', 'auer', 'te', '▁die', '▁SP', 'D', '▁ihr', '▁Nein', '▁zu', '▁einer', '▁von', '▁der', '▁CS', 'U', '▁geforder', 'ten', '▁P', 'kw', '-M', 'aut', '.']\n",
      "Input tensor shape: torch.Size([1, 38])\n",
      "Input indices: [20176, 6747, 7487, 18, 3899, 3804, 4584, 21719, 4012, 3942, 3829, 6184, 4086, 6049, 15944, 4225, 83, 7301, 3801, 3827, 12758, 42, 4455, 28599, 3901, 4207, 3923, 3829, 20817, 59, 11614, 3865, 3846, 29016, 5170, 4946, 20, 2]\n",
      "Generated 34 tokens\n",
      "Predicted indices: [1, 15604, 5358, 3823, 6355, 4071, 3838, 4017, 12578, 4037, 3998, 20368, 23916, 3790, 12758, 42, 6095, 4111, 14741, 3908, 3950, 4376, 3836, 19036, 3826, 4082, 3774, 6463, 3815, 3790, 16470, 4299, 20, 2]\n",
      "Input tokens: ['▁Z', 'war', '▁ist', '▁sie', '▁un', 'fr', 'ucht', 'bar,', '▁hoff', 't', '▁aller', 'dings,', '▁durch', '▁Ad', 'opt', 'ion', '▁oder', '▁eine', '▁Le', 'i', 'hm', 'utter', '▁ein', '▁Kind', '▁bekommen', '▁zu', '▁können.']\n",
      "Input tensor shape: torch.Size([1, 28])\n",
      "Input indices: [3968, 5566, 3937, 4189, 3810, 4662, 6110, 10875, 6545, 90, 5559, 28502, 4259, 6275, 13151, 3802, 4166, 3991, 4390, 79, 5008, 10015, 3840, 12123, 11004, 3901, 18049, 2]\n",
      "Generated 37 tokens\n",
      "Predicted indices: [1, 7085, 3838, 8589, 3908, 3950, 3838, 3810, 90, 4711, 3826, 3823, 4026, 3790, 4645, 4439, 3953, 3796, 6784, 3815, 3998, 6919, 4009, 3774, 6473, 4886, 3950, 3838, 3796, 5034, 5193, 3823, 9383, 3774, 5853, 20, 2]\n",
      "Input tokens: [\"▁'\", 'F', 'ür', '▁mich', '▁wäre', '▁so', '▁eine', '▁Wohn', 'gemeinschaft', '▁aber', '▁nichts', \"',\", '▁mein', 't', '▁sie', '▁mit', '▁einem', '▁Augen', 'zw', 'ink', 'ern', '.']\n",
      "Input tensor shape: torch.Size([1, 23])\n",
      "Input indices: [4925, 44, 3895, 5292, 6250, 3959, 3991, 7811, 16537, 4490, 7702, 10920, 4915, 90, 4189, 3952, 4325, 9142, 8568, 4456, 4060, 20, 2]\n",
      "Generated 26 tokens\n",
      "Predicted indices: [1, 3862, 4312, 3836, 3957, 3774, 8772, 3815, 15882, 18, 4273, 9113, 10332, 4312, 3836, 3774, 8772, 3815, 13626, 3823, 13626, 4644, 3774, 18568, 20, 2]\n",
      "Input tokens: ['▁Die', '▁Kl', 'user', '-A', 'mp', 'el', '▁sichere', '▁sowohl', '▁Rad', 'fahrer', '▁als', '▁auch', '▁Bus', 'fahr', 'gäste', '▁und', '▁die', '▁Berg', 'le', '-Be', 'wohner', '.']\n",
      "Input tensor shape: torch.Size([1, 23])\n",
      "Input indices: [4260, 8607, 28704, 5304, 4327, 3847, 20207, 6592, 8573, 21397, 3990, 4078, 6615, 4571, 22836, 3830, 3827, 9387, 3807, 16835, 13024, 20, 2]\n",
      "Generated 18 tokens\n",
      "Predicted indices: [1, 4610, 5147, 10180, 5991, 3815, 5297, 5735, 3822, 6615, 3979, 5543, 18234, 3822, 4884, 4570, 20, 2]\n",
      "Input tokens: ['▁Die', '▁Stadt', '▁Ge', 'ising', 'en', '▁wurde', '▁in', '▁einer', '▁Sch', 'enk', 'ungs', 'ur', 'kun', 'de,', '▁die', '▁im', '▁Besitz', '▁des', '▁Kl', 'ost', 'ers', '▁St.', '▁G', 'allen', '▁ist,', '▁im', '▁Jahre', '▁7', '64', '▁erstmals', '▁ur', 'kund', 'lich', '▁erwähnt', '.']\n",
      "Input tensor shape: torch.Size([1, 36])\n",
      "Input indices: [4260, 5873, 4230, 6284, 3771, 4475, 3796, 4207, 4087, 6445, 4086, 3805, 5528, 8006, 3827, 3928, 15162, 3948, 8607, 4164, 3916, 10027, 3872, 6003, 4643, 3928, 5789, 5033, 13553, 18780, 6595, 15110, 3884, 13917, 20, 2]\n",
      "Generated 39 tokens\n",
      "Predicted indices: [1, 4610, 5735, 3815, 3774, 11904, 22657, 13228, 4076, 9913, 3796, 3774, 3792, 4710, 18, 4071, 3838, 9913, 3796, 3790, 4823, 4964, 3815, 3790, 4405, 27235, 3815, 3790, 4405, 27235, 3815, 3790, 4405, 27235, 3815, 5033, 13553, 20, 2]\n",
      "Input tokens: ['▁Das', '▁ging', '▁den', '▁Musik', 'ern,', '▁die', '▁den', '▁Fest', 'akt', '▁um', 'ra', 'hm', 'ten,', '▁genauso', '▁wie', '▁so', '▁man', 'chem', '▁Redner', '.']\n",
      "Input tensor shape: torch.Size([1, 21])\n",
      "Input indices: [4646, 13038, 3903, 8124, 5836, 3827, 3903, 6778, 5494, 4091, 3849, 5008, 5598, 15649, 4138, 3959, 4149, 13423, 17515, 20, 2]\n",
      "Generated 24 tokens\n",
      "Predicted indices: [1, 4610, 4645, 4439, 4040, 4328, 8238, 4647, 3790, 4626, 3815, 3790, 4626, 3957, 4653, 3957, 3908, 3815, 3774, 5232, 3815, 17548, 20, 2]\n",
      "Input tokens: ['▁Mir', '▁ist', '▁klar', '▁geworden,', '▁dass', '▁ich', '▁falsch', '▁gehandelt', '▁habe', '.']\n",
      "Input tensor shape: torch.Size([1, 11])\n",
      "Input indices: [15802, 3937, 6661, 23567, 4042, 4162, 15659, 28047, 5327, 20, 2]\n",
      "Generated 13 tokens\n",
      "Predicted indices: [1, 3862, 4040, 4939, 3950, 5203, 3908, 3862, 4040, 4328, 11400, 20, 2]\n",
      "Input tokens: ['▁Doch', '▁mit', '▁dem', '▁S', 'inken', '▁der', '▁Zust', 'immungs', 'werte', '▁für', '▁Obama', '▁auf', '▁unter', '▁45', '▁%', '▁diese', '▁Woche', '▁ist', '▁die', '▁Rückkehr', '▁ins', '▁Jahr', '▁2008', '▁durch', '▁dieses', '▁Buch', '▁um', '▁so', '▁h', 'är', 'ter', '▁geworden', '.']\n",
      "Input tensor shape: torch.Size([1, 34])\n",
      "Input indices: [13484, 3952, 3997, 3817, 19928, 3829, 7465, 17447, 11534, 3944, 16259, 3942, 4225, 12355, 5978, 4358, 9612, 3937, 3827, 19222, 4633, 4422, 6332, 4259, 4781, 7508, 4091, 3959, 3811, 4239, 3851, 11556, 20, 2]\n",
      "Generated 38 tokens\n",
      "Predicted indices: [1, 13689, 3941, 3790, 5485, 4882, 5468, 3815, 3790, 4730, 3987, 4952, 3887, 3774, 9232, 4861, 7750, 3941, 3774, 7439, 3823, 3790, 4730, 4427, 3815, 3998, 16042, 3887, 3774, 4484, 4037, 3790, 4484, 3815, 3998, 16042, 20, 2]\n",
      "Input tokens: ['▁Wahr', 'scheinlich', '▁werden', '▁wir', '▁bald', '▁verstehen,', '▁warum', '▁sich', '▁der', '▁Schw', 'anz', '▁mal', '▁in', '▁die', '▁eine', ',', '▁mal', '▁in', '▁die', '▁andere', '▁Richtung', '▁bewegt']\n",
      "Input tensor shape: torch.Size([1, 23])\n",
      "Input indices: [9660, 11111, 4075, 3933, 11068, 16660, 10946, 4025, 3829, 6126, 4295, 9258, 3796, 3827, 3991, 18, 9258, 3796, 3827, 5364, 8094, 26058, 2]\n",
      "Generated 20 tokens\n",
      "Predicted indices: [1, 7085, 3838, 11023, 6942, 4152, 3908, 3943, 4056, 4990, 3790, 10691, 3772, 4270, 3947, 3788, 3796, 6431, 20, 2]\n",
      "Input tokens: ['▁Die', '▁Wahrschein', 'lichkeit,', '▁dass', '▁unbe', 'f', 'ug', 'te', '▁Personen', '▁eine', '▁Mail', '▁mit', 'les', 'en,', '▁ist', '▁äußerst', '▁ger', 'ing.']\n",
      "Input tensor shape: torch.Size([1, 19])\n",
      "Input indices: [4260, 28300, 18679, 4042, 10688, 76, 4010, 3801, 7884, 3991, 13015, 3952, 4849, 3855, 3937, 9564, 5066, 9022, 2]\n",
      "Generated 22 tokens\n",
      "Predicted indices: [1, 4610, 4723, 11023, 6983, 3908, 3810, 19388, 3794, 5210, 4111, 4328, 18814, 3941, 3804, 23297, 19087, 3838, 7995, 8038, 20, 2]\n",
      "Input tokens: ['▁Der', '▁Ve', 'get', 'arier', 'b', 'und', '▁Deutschland', '▁schlägt', '▁anlässlich', '▁des', '▁Welt', 've', 'g', 'ant', 'ags', '▁am', '▁1.', '▁November', '▁eine', '▁Reihe', '▁von', '▁ve', 'gan', 'en', '▁Alternativen', '▁vor', ':']\n",
      "Input tensor shape: torch.Size([1, 28])\n",
      "Input indices: [4899, 13991, 5151, 25633, 72, 4005, 7203, 18120, 29894, 3948, 5233, 3951, 77, 4013, 15171, 4153, 6984, 7923, 3991, 8125, 3923, 7152, 4384, 3771, 25036, 4108, 32, 2]\n",
      "Generated 23 tokens\n",
      "Predicted indices: [1, 4610, 3817, 8197, 54, 6095, 3838, 19088, 3774, 9649, 3815, 19914, 3854, 4315, 4043, 3790, 7063, 6304, 3900, 3961, 7923, 32, 2]\n",
      "Input tokens: ['▁Bei', '▁den', '▁Damen', '▁war', '▁es', '▁Ther', 'esa', '▁D', 'uell', 'i', '▁vom', '▁Team', '▁Alb', 'tra', 'um,', '▁die', '▁es', '▁ganz', '▁oben', '▁aufs', '▁Sieg', 'ert', 're', 'pp', 'chen', '▁schaff', 'te', '.']\n",
      "Input tensor shape: torch.Size([1, 29])\n",
      "Input indices: [6858, 3903, 8220, 4304, 4045, 11682, 26149, 3866, 7524, 79, 4724, 8619, 18881, 4249, 7475, 3827, 4045, 5075, 12016, 19951, 20628, 4181, 3791, 3970, 4394, 9114, 3801, 20, 2]\n",
      "Generated 28 tokens\n",
      "Predicted indices: [1, 4610, 3866, 4930, 3790, 8158, 18755, 3950, 4076, 3774, 4149, 4439, 4076, 3774, 7541, 3815, 7541, 18, 4071, 3838, 4436, 6719, 4193, 3822, 4323, 12416, 20, 2]\n",
      "Input tokens: ['▁Heute', '▁gibt', '▁es', '▁auch', '▁für', '▁den', '▁al', 'ters', 'gere', 'chten', '▁Um', 'bau', '▁Spezialisten', '.']\n",
      "Input tensor shape: torch.Size([1, 15])\n",
      "Input indices: [16173, 4926, 4045, 4078, 3944, 3903, 3918, 5505, 11211, 5396, 4747, 6119, 27990, 20, 2]\n",
      "Generated 15 tokens\n",
      "Predicted indices: [1, 9474, 3946, 4283, 3838, 4183, 3774, 4466, 3887, 13745, 3823, 4968, 8238, 20, 2]\n",
      "Input tokens: ['▁Diese', '▁Be', 'iden', '▁konnten', '▁setz', 'ten', '▁sich', '▁er', 'wart', 'ungs', 'gemäß', '▁vom', '▁Feld', '▁ab', '.']\n",
      "Input tensor shape: torch.Size([1, 16])\n",
      "Input indices: [6349, 4121, 4865, 11172, 14328, 3865, 4025, 3939, 9462, 4086, 12514, 4724, 14344, 4058, 20, 2]\n",
      "Generated 16 tokens\n",
      "Predicted indices: [1, 13846, 4647, 5500, 3823, 3836, 5500, 3823, 8083, 3908, 3950, 4076, 14453, 12109, 20, 2]\n",
      "Input tokens: ['▁Der', '▁Bör', 'sen', 'bet', 'reiber', '▁N', 'as', 'da', 'q', '▁O', 'M', 'X', '▁hält', '▁seine', '▁Kunden', '▁weiter', '▁in', '▁A', 'tem', '.']\n",
      "Input tensor shape: torch.Size([1, 21])\n",
      "Input indices: [4899, 15596, 7264, 7067, 11760, 3956, 3806, 14894, 87, 4074, 51, 62, 14146, 5155, 6207, 5004, 3796, 3832, 5571, 20, 2]\n",
      "Generated 20 tokens\n",
      "Predicted indices: [1, 4610, 10422, 9250, 17694, 13, 6871, 3815, 3956, 44, 51, 4074, 51, 18091, 3838, 14523, 4729, 11842, 20, 2]\n",
      "Input tokens: ['▁Neue', '▁Flugzeuge', '▁sind', '▁weitaus', '▁abhäng', 'iger', '▁von', '▁elektr', 'ischen', '▁Systemen', '▁als', '▁früh', 'ere', '▁Generationen', '▁von', '▁Luft', 'fahrzeug', 'en,', '▁aber', '▁sie', '▁sind', '▁auch', '▁so', '▁konstru', 'iert', '▁und', '▁von', '▁der', '▁FA', 'A', '▁genehm', 'igt,', '▁dass', '▁ihnen', '▁elektronische', '▁Inter', 'ferenz', 'en', '▁nichts', '▁aus', 'mach', 'en.']\n",
      "Input tensor shape: torch.Size([1, 43])\n",
      "Input indices: [21111, 28036, 4093, 25746, 13157, 4712, 3923, 20453, 3986, 22597, 3990, 12889, 3902, 21322, 3923, 8743, 28255, 3855, 4490, 4189, 4093, 4078, 3959, 13495, 4298, 3830, 3923, 3829, 18213, 39, 20103, 6980, 4042, 6756, 23266, 5211, 6439, 3771, 7702, 4048, 14759, 7414, 2]\n",
      "Generated 43 tokens\n",
      "Predicted indices: [1, 6948, 6840, 3778, 9545, 5769, 4323, 3900, 3790, 23008, 7006, 4718, 11254, 4173, 3887, 15274, 16458, 4718, 11254, 4173, 4273, 4461, 3953, 4183, 21979, 6920, 3822, 11966, 4037, 3790, 18379, 3832, 3875, 4754, 3908, 11499, 4433, 7033, 3838, 4017, 4939, 20, 2]\n",
      "Input tokens: ['▁Aber', '▁es', '▁ist', '▁einfach', '▁nicht', 's,', '▁was', '▁ich', '▁mir', '▁hätte', '▁vorstellen', '▁können.']\n",
      "Input tensor shape: torch.Size([1, 13])\n",
      "Input indices: [9173, 4045, 3937, 5521, 4012, 3988, 4076, 4162, 5664, 9116, 25852, 18049, 2]\n",
      "Generated 13 tokens\n",
      "Predicted indices: [1, 13689, 3950, 3838, 7604, 4017, 7585, 3823, 4040, 4636, 8244, 20, 2]\n",
      "Input tokens: ['▁Die', '▁Messe', '▁wird', '▁im', '▁Rahmen', '▁der', '▁Gottes', 'dienste', '▁aufge', 'führt,', '▁wie', '▁der', '▁Auftraggeber', '▁Johann', '▁Philipp', '▁Ne', 'um', 'ann', '▁es', '▁im', '▁Sinn', '▁hatte', '.']\n",
      "Input tensor shape: torch.Size([1, 24])\n",
      "Input indices: [4260, 13508, 4109, 3928, 5670, 3829, 20398, 17979, 6828, 12615, 4138, 3829, 26623, 15681, 19697, 4822, 3871, 4007, 4045, 3928, 12049, 7283, 20, 2]\n",
      "Generated 20 tokens\n",
      "Predicted indices: [1, 4610, 22357, 5790, 3838, 5027, 13936, 4400, 5252, 3790, 7292, 3815, 3790, 11724, 13, 3784, 29871, 4069, 20, 2]\n",
      "Input tokens: ['▁Die', '▁Leute', '▁bezahlen', '▁direkt', '▁für', '▁das,', '▁was', '▁sie', '▁bekommen', '.']\n",
      "Input tensor shape: torch.Size([1, 11])\n",
      "Input indices: [4260, 11602, 22318, 6850, 3944, 10867, 4076, 4189, 11004, 20, 2]\n",
      "Generated 14 tokens\n",
      "Predicted indices: [1, 4610, 4645, 6021, 4321, 7484, 3823, 4671, 4461, 4040, 4328, 10580, 20, 2]\n",
      "Input tokens: ['▁Jetzt', '▁wird', '▁wegen', '▁der', '▁An', 'schuld', 'igung', '▁er', 'mittel', 't,', '▁Tr', 'ip', 'od', 'i', '▁habe', '▁von', '▁O', 'be', 'ids', '▁ver', 'deck', 'tem', '▁Interesse', '▁an', '▁den', '▁Grund', 'stück', 'en', '▁gew', 'usst', ',', '▁nachdem', '▁Tr', 'ip', 'od', 'is', '▁früh', 'ere', '▁stell', 'ver', 'treten', 'de', '▁St', 'ab', 'sche', 'fin', '▁L', 'yn', 'ne', '▁As', 'h', 'p', 'ole', '▁am', '▁Donnerstag', '▁entsprechend', '▁ausges', 'agt', '▁hatte', '.']\n",
      "Input tensor shape: torch.Size([1, 61])\n",
      "Input indices: [20633, 4109, 8903, 3829, 4038, 16030, 4981, 3939, 5192, 3974, 6251, 4115, 4057, 79, 5327, 3923, 4074, 4184, 12663, 3938, 9099, 5571, 8272, 3804, 3903, 4956, 7802, 3771, 4650, 8188, 18, 11870, 6251, 4115, 4057, 3783, 12889, 3902, 9888, 3940, 7154, 3912, 3989, 3889, 4631, 4852, 3913, 5516, 4016, 5447, 78, 86, 8544, 4153, 18730, 10617, 13599, 14580, 7283, 20, 2]\n",
      "Generated 48 tokens\n",
      "Predicted indices: [1, 22378, 3949, 3946, 3988, 3943, 4040, 5354, 3823, 4378, 92, 6005, 3790, 4549, 6285, 4129, 3815, 4074, 4676, 4176, 8247, 9912, 3988, 4071, 4076, 16989, 4043, 3790, 7594, 3815, 3790, 4074, 3854, 4265, 3913, 5516, 4016, 3913, 5516, 4016, 12093, 3779, 4265, 3913, 5516, 4016, 20, 2]\n",
      "Input tokens: ['▁Be', 'vor', '▁es', '▁wieder', '▁zurück', '▁ans', '▁Tages', 'licht', '▁geht,', '▁lässt', '▁Schul', 'ze', '▁die', '▁Teilnehmer', '▁auf', '▁der', '▁oberen', '▁Par', 'ke', 'bene', '▁noch', '▁einen', '▁Blick', '▁in', '▁einen', '▁fin', 'ster', 'en,', '▁15', '▁Meter', '▁tie', 'fen', '▁Sch', 'acht', '▁wer', 'fen', '.']\n",
      "Input tensor shape: torch.Size([1, 38])\n",
      "Input indices: [4121, 5070, 4045, 5045, 5758, 6962, 8080, 9603, 11599, 9260, 7849, 4077, 3827, 13630, 3942, 3829, 25536, 4144, 4494, 6659, 4444, 4238, 8200, 3796, 4238, 4374, 5039, 3855, 5336, 12502, 17319, 4413, 4087, 4744, 4014, 4413, 20, 2]\n",
      "Generated 32 tokens\n",
      "Predicted indices: [1, 4121, 4680, 3790, 5560, 5154, 13881, 8419, 5242, 24203, 3953, 5397, 8474, 3796, 3774, 4691, 5323, 3815, 4027, 92, 9218, 4417, 3815, 3774, 28167, 18, 5336, 8565, 6472, 6953, 20, 2]\n",
      "Input tokens: ['▁Er', '▁prä', 'gte', '▁den', '▁Begriff', '▁„', 'gesch', 'le', 'cht', 'liche', '▁Identität', '“', '▁und', '▁argument', 'ierte,', '▁soziale', '▁und', '▁umwelt', 'beding', 'te', '▁An', 'st', 'öße', '▁–', '▁wie', '▁die', '▁Eltern', '▁ein', '▁Kind', '▁er', 'ziehen', '▁–', '▁inter', 'ag', 'ierten', '▁mit', '▁den', '▁Gen', 'en', '▁und', '▁H', 'orm', 'onen', '▁eines', '▁Kindes', '▁und', '▁prä', 'gten', '▁so,', '▁ob', '▁sich', '▁eine', '▁Person', '▁als', '▁m', 'änn', 'lich', '▁oder', '▁weib', 'lich', '▁betrachte', '.']\n",
      "Input tensor shape: torch.Size([1, 63])\n",
      "Input indices: [4167, 12379, 23474, 3903, 12574, 4971, 5179, 3807, 4305, 4336, 18161, 1239, 3830, 13959, 20490, 9438, 3830, 14225, 20167, 3801, 4038, 3834, 11283, 4330, 4138, 3827, 15757, 3840, 12123, 3939, 12489, 4330, 4437, 4031, 5376, 3952, 3903, 5622, 3771, 3830, 3892, 6296, 12053, 4698, 28577, 3830, 12379, 24161, 10270, 4423, 4025, 3991, 5526, 3990, 3800, 26919, 3884, 4166, 26897, 3884, 11881, 20, 2]\n",
      "Generated 49 tokens\n",
      "Predicted indices: [1, 7085, 3838, 3774, 3808, 3999, 3908, 3790, 7121, 3825, 7043, 5147, 4010, 8783, 3916, 3953, 8238, 3796, 3774, 7091, 17815, 3822, 8956, 16068, 3815, 7038, 11889, 5370, 3822, 7661, 6200, 4605, 3957, 18511, 13, 18511, 3823, 3836, 4437, 7033, 3941, 3790, 22740, 3822, 3892, 6296, 4406, 20, 2]\n",
      "Input tokens: ['▁Die', '▁Ergebnisse', '▁b', 'lieben', '▁hinter', '▁den', '▁Pro', 'gn', 'osen', '▁zurück', '▁und', '▁führ', 'ten', '▁zu', '▁einem', '▁Kurs', 'st', 'urz', '▁von', '▁über', '▁acht', '▁Prozent', '▁an', '▁der', '▁Börse', '▁von', '▁Tor', 'ont', 'o.']\n",
      "Input tensor shape: torch.Size([1, 30])\n",
      "Input indices: [4260, 9446, 3792, 18229, 8634, 3903, 4103, 8665, 9272, 5758, 3830, 5326, 3865, 3901, 4325, 13592, 3834, 6136, 3923, 4062, 14757, 11513, 3804, 3829, 20083, 3923, 11689, 4370, 17701, 2]\n",
      "Generated 26 tokens\n",
      "Predicted indices: [1, 4610, 7676, 7446, 9515, 22531, 13262, 3822, 7405, 3823, 3774, 5300, 3815, 14983, 4371, 5057, 3815, 3790, 10422, 9250, 3815, 3790, 10422, 9250, 20, 2]\n",
      "Input tokens: ['▁Einige', '▁Titel', '▁sind', '▁im', '▁He', 'y', 'ne', '▁Verlag', '▁erschien', 'en,', '▁die', '▁H', 'aff', 'mans', '-K', 'ass', 'ette', '▁mit', '▁den', '▁11', '8', '▁Er', 'zähl', 'ungen', '▁vertre', 'ibt', '▁Z', 'weit', 'ausende', 'ins', '.']\n",
      "Input tensor shape: torch.Size([1, 32])\n",
      "Input indices: [17867, 13353, 4093, 3928, 5115, 95, 4016, 27751, 25611, 3855, 3827, 3892, 5030, 29385, 5915, 4047, 7979, 3952, 3903, 6178, 30, 4167, 13012, 4000, 15326, 4669, 3968, 5228, 14569, 5772, 20, 2]\n",
      "Generated 34 tokens\n",
      "Predicted indices: [1, 27280, 14769, 4647, 6034, 3796, 5115, 95, 4743, 4146, 4076, 3774, 22265, 3823, 4784, 11409, 3815, 3790, 9933, 12873, 15324, 18, 3941, 3790, 6178, 30, 7304, 7183, 3815, 12262, 3815, 4645, 20, 2]\n",
      "Input tokens: ['▁Am', '▁Ende', '▁präsent', 'ierte', '▁Pf', 'arr', 'gemein', 'der', 'at', '▁Michael', '▁Schön', 'er', '▁aus', '▁Stein', 'ach', '▁das', '▁neue', '▁Log', 'o', '▁der', '▁Se', 'els', 'orge', 'ein', 'heit,', '▁dem', '▁mit', '▁deut', 'licher', '▁Mehrheit', '▁zugestimmt', '▁wurde.']\n",
      "Input tensor shape: torch.Size([1, 33])\n",
      "Input indices: [5416, 6665, 10722, 5268, 8069, 12370, 6579, 3859, 3786, 14294, 13886, 3772, 4048, 13322, 3922, 3899, 5240, 9707, 85, 3829, 4499, 4952, 8476, 3917, 12105, 3997, 3952, 5765, 5446, 9508, 28535, 24929, 2]\n",
      "Generated 40 tokens\n",
      "Predicted indices: [1, 7008, 3790, 4950, 3815, 3790, 3808, 4176, 3806, 4018, 8028, 6619, 7988, 12152, 5235, 4082, 3929, 6296, 4135, 18, 3790, 4398, 7325, 3909, 3815, 3790, 3817, 3993, 14162, 4322, 25409, 4071, 4076, 9697, 3823, 3774, 5203, 8675, 20, 2]\n",
      "Input tokens: ['▁Ich', '▁bin', '▁ermut', 'igt', '▁von', '▁der', '▁Res', 'on', 'anz', '▁auf', '▁mein', '▁politisches', '▁Hand', 'eln,', '▁sowohl', '▁in', '▁den', '▁USA', '▁als', '▁auch', '▁anders', 'wo', '.']\n",
      "Input tensor shape: torch.Size([1, 24])\n",
      "Input indices: [5197, 5813, 16896, 4894, 3923, 3829, 6098, 3779, 4295, 3942, 4915, 21592, 5135, 9091, 6592, 3796, 3903, 6379, 3990, 4078, 11501, 4474, 20, 2]\n",
      "Generated 25 tokens\n",
      "Predicted indices: [1, 3862, 4153, 18830, 3823, 4836, 3774, 5535, 6974, 3823, 4636, 5165, 4897, 3822, 3823, 4211, 3959, 3796, 3790, 6265, 4817, 3822, 18144, 20, 2]\n",
      "Input tokens: ['▁\"Wir', '▁werden', '▁nicht', '▁am', '▁Wild', 'card', '-Ver', 'fahren', '▁teilnehmen', '\",', '▁sagte', '▁Ex', '-N', 'ational', 'spiel', 'er', '▁P', 'asc', 'al', '▁Roll', 'er,', '▁der', '▁seit', '▁2012', '▁das', '▁Konzept', '▁für', '▁einen', '▁Pro', 'fic', 'lub', '▁in', '▁der', '▁Hans', 'est', 'adt', '▁auf', 'stell', 't.']\n",
      "Input tensor shape: torch.Size([1, 40])\n",
      "Input indices: [4596, 4075, 4012, 4153, 16848, 22117, 11302, 5635, 15383, 4624, 13541, 5180, 9058, 4191, 9384, 3772, 3846, 11154, 3794, 14820, 4401, 3829, 5667, 17448, 3899, 11968, 3944, 4238, 4103, 5324, 25551, 3796, 3829, 16506, 3905, 5177, 3942, 4807, 9889, 2]\n",
      "Generated 46 tokens\n",
      "Predicted indices: [1, 4623, 4303, 4439, 3953, 4017, 21475, 3796, 3790, 15447, 3905, 5193, 14041, 4056, 3836, 8238, 3796, 3790, 17443, 75, 3815, 3790, 3919, 20180, 5127, 3815, 3774, 3919, 5047, 3822, 3790, 9960, 3815, 3774, 3919, 4117, 4106, 3796, 3790, 13319, 3815, 4464, 23762, 81, 20, 2]\n",
      "Input tokens: ['▁Am', '▁sp', 'äten', '▁Donnerstag', 'abend', '▁hatte', '▁es', '▁im', '▁Erd', 'geschoss', '▁des', '▁Hauses', '▁geb', 'r', 'annt', '.']\n",
      "Input tensor shape: torch.Size([1, 17])\n",
      "Input indices: [5416, 4270, 14109, 18730, 27748, 7283, 4045, 3928, 10976, 26606, 3948, 13670, 5175, 88, 5892, 20, 2]\n",
      "Generated 19 tokens\n",
      "Predicted indices: [1, 7008, 18357, 4043, 3790, 4950, 3815, 18357, 18, 3950, 4076, 3790, 4723, 4246, 3815, 3790, 6631, 20, 2]\n",
      "Input tokens: ['▁Wohn', 'ungs', 'br', 'and', '▁in', '▁Hel', 'mb', 'rechts', ':', '▁Rett', 'ungs', 'kräfte', '▁ber', 'gen', '▁verk', 'ohl', 'te', '▁Le', 'iche']\n",
      "Input tensor shape: torch.Size([1, 20])\n",
      "Input indices: [7811, 4086, 5417, 3907, 3796, 11014, 5174, 8328, 32, 22223, 4086, 14464, 4478, 3911, 15652, 5454, 3801, 4390, 13632, 2]\n",
      "Generated 23 tokens\n",
      "Predicted indices: [1, 4402, 18342, 3796, 11014, 4116, 6099, 3823, 29348, 5505, 32, 28919, 11295, 3822, 3790, 4390, 83, 6291, 3815, 4390, 83, 20, 2]\n",
      "Input tokens: ['▁\"N', 'ie', 'mand', '▁kann', '▁uns', '▁verb', 'ieten', '▁daran', '▁zu', '▁glauben,', '▁auch', '▁gegen', '▁das', '▁beste', '▁Team', '▁Europas', '▁der', '▁vergangenen', '▁beiden', '▁Jahre', '▁zu', '▁gewinnen', '\",', '▁b', 'il', 'anz', 'ierte', '▁Bay', 'ern', '-C', 'o', 'ach', '▁S', 'vet', 'is', 'lav', '▁P', 'es', 'ic', '▁nach', '▁dem', '▁un', 'glück', 'lichen', '▁8', '3', ':', '88', '▁(3', '9', ':4', '7)', '▁am', '▁Donnerstag', 'abend', '▁bei', '▁Titel', 'ver', 'teid', 'iger', '▁Olymp', 'i', 'ak', 'os', '▁Pir', 'äus', '.']\n",
      "Input tensor shape: torch.Size([1, 68])\n",
      "Input indices: [5156, 3787, 11519, 4352, 4065, 4935, 7658, 8186, 3901, 16070, 4078, 4597, 3899, 5079, 8619, 7618, 3829, 10007, 7072, 5789, 3901, 15414, 4624, 3792, 3854, 4295, 5268, 13319, 4060, 6457, 85, 3922, 3817, 28250, 3783, 9193, 3846, 3778, 3835, 4234, 3997, 3810, 23327, 4209, 5061, 25, 32, 16788, 13490, 31, 29434, 12426, 4153, 18730, 27748, 4241, 13353, 3940, 8649, 4712, 12184, 79, 3993, 3909, 23539, 7595, 20, 2]\n",
      "Generated 79 tokens\n",
      "Predicted indices: [1, 7085, 3838, 3774, 6029, 3908, 3943, 4148, 10825, 11008, 5286, 3790, 4655, 4185, 7541, 3815, 4096, 3823, 10138, 3790, 6819, 10186, 4626, 3815, 3790, 13319, 3815, 3850, 5531, 4948, 3822, 3817, 3835, 81, 78, 5114, 3854, 4265, 4032, 5154, 3790, 28524, 3822, 4065, 81, 17293, 25, 16788, 4032, 3817, 3993, 14162, 4322, 25409, 5060, 41, 16912, 10371, 12835, 22, 4032, 23553, 25, 18357, 18, 6619, 4294, 3993, 79, 3822, 3790, 23297, 19087, 3796, 3790, 4402, 4344, 20, 2]\n",
      "Input tokens: ['▁L', 'etz', 'tendlich', '▁entscheid', 'et', '▁das', '▁Kind', '▁über', '▁das', '▁Geschle', 'cht,', '▁das', '▁besser', '▁zu', '▁ihm', '▁passt', '▁–', '▁und', '▁das', '▁ist', '▁wunder', 'bar', '.']\n",
      "Input tensor shape: torch.Size([1, 24])\n",
      "Input indices: [3913, 4151, 17154, 9069, 3856, 3899, 12123, 4062, 3899, 23363, 12066, 3899, 7615, 3901, 7368, 24978, 4330, 3830, 3899, 3937, 8984, 4438, 20, 2]\n",
      "Generated 23 tokens\n",
      "Predicted indices: [1, 15467, 4890, 3790, 5853, 3838, 3774, 6690, 4071, 3838, 3823, 3836, 8382, 3900, 3790, 16609, 3815, 17054, 3822, 3838, 11928, 20, 2]\n",
      "Input tokens: ['▁Ob', 'am', 'as', '▁Rück', 'zie', 'her', '▁in', '▁der', '▁Gesundheit', 'spolitik']\n",
      "Input tensor shape: torch.Size([1, 11])\n",
      "Input indices: [7679, 3863, 3806, 7101, 4837, 4192, 3796, 3829, 7001, 7611, 2]\n",
      "Generated 12 tokens\n",
      "Predicted indices: [1, 8165, 4317, 3950, 3838, 3774, 4730, 17372, 3790, 6131, 5300, 2]\n",
      "Input tokens: ['▁Das', '▁Al', 'ten', 'werk', '▁Leip', 'fer', 'ding', 'en', '▁wird', '▁40', '▁Jahre', '▁al', 't,', '▁die', '▁Ge', 'ising', 'er', '▁Schule', '▁ist', '▁seit', '▁50', '▁Jahren', '▁am', '▁neuen', '▁Standort', '▁und', '▁fe', 'iert', '▁dies', '▁am', '▁10.', '▁Ma', 'i,', '▁der', '▁Musik', 'verein', '▁Poly', 'h', 'ym', 'n', 'ia', '▁Leip', 'fer', 'ding', 'en', '▁wird', '▁150', '▁Jahre', '▁alt', '▁und', '▁fe', 'iert', '▁dies', '▁im', '▁Rahmen', '▁des', '▁Brun', 'nen', 'fest', 'es', '▁vom', '▁4.', '▁bis', '▁7.', '▁Juli', '.']\n",
      "Input tensor shape: torch.Size([1, 67])\n",
      "Input indices: [4646, 4528, 3865, 6557, 20620, 4107, 8002, 3771, 4109, 7476, 5789, 3918, 3974, 3827, 4230, 6284, 3772, 16603, 3937, 5667, 6373, 5465, 4153, 5369, 16066, 3830, 4485, 4298, 3966, 4153, 17139, 4639, 5235, 3829, 8124, 13840, 20147, 78, 7504, 84, 4171, 20620, 4107, 8002, 3771, 4109, 11605, 5789, 13845, 3830, 4485, 4298, 3966, 3928, 5670, 3948, 21386, 4019, 14629, 3778, 4724, 15247, 4541, 17212, 10565, 20, 2]\n",
      "Generated 60 tokens\n",
      "Predicted indices: [1, 4610, 4528, 3865, 3772, 16803, 3815, 7665, 3838, 5027, 10580, 3887, 7476, 5377, 5830, 3790, 7579, 3815, 3774, 8419, 8419, 18, 3822, 3790, 12587, 23006, 3904, 3808, 4572, 4388, 3815, 3790, 4099, 9780, 14210, 4940, 3848, 4171, 3838, 6960, 3823, 3836, 6346, 6629, 11605, 5377, 6587, 18, 3822, 3790, 12587, 23006, 3904, 4488, 23949, 3815, 4530, 11524, 20, 2]\n",
      "Input tokens: ['▁Mitglieder', '▁des', '▁FA', 'A', '-Ber', 'at', 'ungsk', 'om', 'ite', 'es', '▁äußer', 'ten', '▁gem', 'isch', 'te', '▁Gefü', 'h', 'le,', '▁was', '▁das', '▁Risiko', '▁bei', '▁der', '▁Nutzung', '▁von', '▁Geräten', '▁ange', 'ht', '.']\n",
      "Input tensor shape: torch.Size([1, 30])\n",
      "Input indices: [8547, 3948, 18213, 39, 16752, 3786, 18916, 3828, 4289, 3778, 8566, 3865, 4656, 3896, 3801, 28164, 78, 5098, 4076, 3899, 13728, 4241, 3829, 9024, 3923, 29961, 4976, 4414, 20, 2]\n",
      "Generated 25 tokens\n",
      "Predicted indices: [1, 7799, 3815, 3790, 5968, 3900, 19203, 3822, 24885, 11142, 4647, 23393, 4400, 6015, 3957, 3790, 7316, 3815, 3790, 4686, 3815, 3790, 9708, 20, 2]\n",
      "Input tokens: ['▁Das', '▁Treffen', '▁findet', '▁in', '▁der', '▁Town', '▁Hall', '▁mitten', '▁in', '▁Manhatt', 'an', '▁statt', '.']\n",
      "Input tensor shape: torch.Size([1, 14])\n",
      "Input indices: [4646, 14910, 8035, 3796, 3829, 16435, 14617, 16681, 3796, 27249, 3789, 6418, 20, 2]\n",
      "Generated 15 tokens\n",
      "Predicted indices: [1, 4610, 7843, 4056, 4836, 5182, 3796, 3790, 12947, 3815, 3774, 5957, 24615, 20, 2]\n",
      "Input tokens: ['▁20', '▁Jahre', '▁zu', '▁bekommen,', '▁nachdem', '▁er', '▁20', '2', '▁Menschen', '▁getötet', '▁und', '▁viele', '▁Hunder', 'te', '▁verletzt', '▁hat,', '▁ist', '▁nicht', '▁viel', '.']\n",
      "Input tensor shape: torch.Size([1, 21])\n",
      "Input indices: [4652, 5789, 3901, 18824, 11870, 3939, 4652, 24, 4850, 28357, 3830, 5558, 19598, 3801, 23305, 5594, 3937, 4012, 4667, 20, 2]\n",
      "Generated 25 tokens\n",
      "Predicted indices: [1, 12248, 3838, 4477, 11567, 4496, 4652, 24, 18814, 5154, 4146, 4111, 18814, 3822, 4798, 16806, 3815, 12262, 3815, 4645, 4040, 4328, 18814, 20, 2]\n",
      "Input tokens: ['▁Am', '▁Vor', 'mittag', '▁wollte', '▁auch', '▁die', '▁Arbeitsgruppe', '▁Migration', '▁und', '▁Integration', '▁ihre', '▁Beratungen', '▁forts', 'etzen', '.']\n",
      "Input tensor shape: torch.Size([1, 16])\n",
      "Input indices: [5416, 4297, 13759, 13958, 4078, 3827, 27302, 23019, 3830, 9694, 4618, 25747, 21051, 7281, 20, 2]\n",
      "Generated 20 tokens\n",
      "Predicted indices: [1, 7602, 13493, 3790, 6436, 5391, 4076, 4183, 15697, 3887, 3790, 6436, 4616, 3822, 10532, 3815, 4244, 12926, 20, 2]\n",
      "Input tokens: ['▁Das', '▁stör', 'te', '▁die', '▁etwa', '▁20', '▁Mitglieder', '▁der', '▁Bürger', 'initiative', '▁jedoch', '▁wenig', '▁bei', '▁ihrer', '▁Aktion', '.']\n",
      "Input tensor shape: torch.Size([1, 17])\n",
      "Input indices: [4646, 28587, 3801, 3827, 7251, 4652, 8547, 3829, 5487, 27074, 5161, 7717, 4241, 5314, 9460, 20, 2]\n",
      "Generated 18 tokens\n",
      "Predicted indices: [1, 21046, 3790, 6265, 4817, 4111, 4017, 4328, 11647, 4037, 4652, 6978, 3815, 3790, 6350, 9770, 20, 2]\n",
      "Input tokens: ['▁20', '14', '▁ist', '▁aber', '▁auch', '▁sonst', '▁ein', '▁Jahr', '▁mit', '▁vielen', '▁J', 'ub', 'il', 'ä', 'en.']\n",
      "Input tensor shape: torch.Size([1, 16])\n",
      "Input indices: [4652, 10693, 3937, 4490, 4078, 10480, 3840, 4422, 3952, 6757, 4033, 4029, 3854, 198, 7414, 2]\n",
      "Generated 15 tokens\n",
      "Predicted indices: [1, 13689, 4652, 10693, 3838, 4183, 3774, 4484, 3941, 4798, 4033, 4029, 3854, 7685, 2]\n",
      "Input tokens: ['▁Nor', 'wegen', ':', '▁Nor', 'weg', 'ischer', '▁Ort', '▁macht', '▁sich', '▁mit', '▁R', 'ies', 'ens', 'pie', 'geln', '▁Licht']\n",
      "Input tensor shape: torch.Size([1, 17])\n",
      "Input indices: [7738, 8953, 32, 7738, 6297, 4992, 7814, 8205, 4025, 3952, 3883, 3870, 4051, 23025, 8796, 11793, 2]\n",
      "Generated 16 tokens\n",
      "Predicted indices: [1, 7738, 5299, 32, 7738, 5299, 3838, 3790, 6029, 3941, 3792, 4322, 4142, 14278, 20, 2]\n",
      "Input tokens: ['▁J', 'um', 'bo', '-H', 'erstell', 'er', '▁st', 'reiten', '▁im', '▁An', 'ges', 'icht', '▁großer', '▁Bestellungen', '▁über', '▁Sitz', 'breite']\n",
      "Input tensor shape: torch.Size([1, 18])\n",
      "Input indices: [4033, 3871, 6102, 6797, 6551, 3772, 3929, 22115, 3928, 4038, 4388, 3897, 9359, 24514, 4062, 7669, 25610, 2]\n",
      "Generated 20 tokens\n",
      "Predicted indices: [1, 4033, 3871, 93, 13105, 17523, 3953, 5508, 3823, 3836, 13838, 13710, 3815, 3790, 12738, 3900, 3790, 7648, 20, 2]\n",
      "Input tokens: ['▁Klicken', '▁Sie', '▁sich', '▁durch', '▁die', '▁Bilder', 'g', 'alerie', '▁zum', '▁Auf', 'rt', 'itt', '▁der', '▁\"', 's', 'ing', 'enden', '▁F', 'öhn', 'w', 'elle', '\"', '.']\n",
      "Input tensor shape: torch.Size([1, 24])\n",
      "Input indices: [22053, 4034, 4025, 4259, 3827, 10310, 77, 18498, 4320, 4441, 10814, 5023, 3829, 3825, 89, 3820, 4609, 3868, 8806, 93, 5160, 8, 20, 2]\n",
      "Generated 25 tokens\n",
      "Predicted indices: [1, 3817, 5169, 3790, 12067, 3815, 3790, 11429, 3815, 3790, 4074, 77, 78, 15430, 6205, 4082, 3790, 4925, 83, 4200, 10856, 16219, 13, 6145, 2]\n",
      "Input tokens: ['▁Fr', 'ü', 'her', '▁wurden', '▁die', '▁älteren', '▁Mit', 'bürger', '▁in', '▁der', '▁R', 'ast', 'stätte', '▁be', 'wir', 'tet', '.']\n",
      "Input tensor shape: torch.Size([1, 18])\n",
      "Input indices: [4969, 222, 4192, 5348, 3827, 21516, 4219, 14440, 3796, 3829, 3883, 4159, 28755, 3836, 4830, 4363, 20, 2]\n",
      "Generated 18 tokens\n",
      "Predicted indices: [1, 3890, 9136, 5290, 4616, 3790, 23049, 3904, 4040, 4328, 7446, 4558, 3887, 3790, 23049, 3904, 20, 2]\n",
      "Input tokens: ['▁Die', '▁staatliche', '▁Mineral', 'öl', 'steuer', '▁von', '▁18', ',', '4', '▁Cent', '▁pro', '▁Gall', 'one', '▁(w', 'en', 'iger', '▁als', '▁4', '▁Eur', 'oc', 'ent', '▁pro', '▁Liter', ')', '▁ist', '▁seit', '▁20', '▁Jahren', '▁nicht', '▁gestiegen', '.']\n",
      "Input tensor shape: torch.Size([1, 32])\n",
      "Input indices: [4260, 19735, 26282, 5659, 16511, 3923, 5450, 18, 26, 7250, 3919, 25742, 4406, 12030, 3771, 4712, 3990, 4530, 7861, 4133, 3814, 3919, 17834, 15, 3937, 5667, 4652, 5465, 4012, 28597, 20, 2]\n",
      "Generated 37 tokens\n",
      "Predicted indices: [1, 3817, 5169, 4652, 26, 21, 4133, 4120, 4952, 3900, 6438, 5014, 4890, 3790, 6438, 3815, 5450, 26, 21, 4133, 4197, 4371, 4484, 4111, 4017, 9445, 3790, 8731, 3815, 6438, 20130, 3870, 3887, 4652, 5377, 20, 2]\n",
      "Input tokens: ['▁Auf', 'schlag', 'bare', '▁Pfl', 'anz', 'ens', 'ah', 'ne', '▁ers', 'etze', '▁herkömm', 'liche', '▁Schlag', 's', 'ah', 'ne', '.']\n",
      "Input tensor shape: torch.Size([1, 18])\n",
      "Input indices: [4441, 8084, 7491, 13040, 4295, 4051, 4003, 4016, 5461, 13073, 25625, 4336, 20786, 89, 4003, 4016, 20, 2]\n",
      "Generated 13 tokens\n",
      "Predicted indices: [1, 4610, 8687, 19850, 89, 3953, 6386, 3900, 8687, 5242, 24203, 20, 2]\n",
      "Input tokens: ['▁Die', '▁meisten', '▁M', 'ails', '▁werden', '▁unterwegs', '▁mehrfach', '▁von', '▁Software', '-R', 'ob', 'o', 'tern', '▁ge', 'les', 'en.']\n",
      "Input tensor shape: torch.Size([1, 17])\n",
      "Input indices: [4260, 7396, 3844, 7124, 4075, 27348, 19832, 3923, 6901, 5895, 4396, 85, 4095, 3926, 4849, 7414, 2]\n",
      "Generated 13 tokens\n",
      "Predicted indices: [1, 25837, 3815, 3790, 9296, 3838, 3776, 11442, 4558, 6816, 8373, 20, 2]\n",
      "Input tokens: ['▁Ich', '▁konnte', '▁gar', '▁nicht', '▁glauben,', '▁dass', '▁sie', '▁wirklich', '▁da', '▁oben', '▁war', '.']\n",
      "Input tensor shape: torch.Size([1, 13])\n",
      "Input indices: [5197, 9183, 5948, 4012, 16070, 4042, 4189, 6706, 4139, 12016, 4304, 20, 2]\n",
      "Generated 14 tokens\n",
      "Predicted indices: [1, 3862, 4076, 4017, 5500, 3823, 5555, 3908, 3950, 4076, 6633, 4691, 20, 2]\n",
      "Input tokens: ['▁Von', '▁der', '▁britischen', '▁Regierung', '▁wurde', '▁eine', '▁Studie', '▁angekünd', 'igt,', '▁die', '▁die', '▁Vorteile', '▁des', '▁H', 'S', '2', '-E', 'isen', 'bahn', 'projekt', 's', '▁für', '▁Schott', 'land', '▁erhöhen', '▁soll', '.']\n",
      "Input tensor shape: torch.Size([1, 28])\n",
      "Input indices: [10803, 3829, 14236, 6225, 4475, 3991, 16534, 19549, 6980, 3827, 3827, 11954, 3948, 3892, 57, 24, 6070, 6561, 8301, 24163, 89, 3944, 27327, 4399, 17316, 4457, 20, 2]\n",
      "Generated 23 tokens\n",
      "Predicted indices: [1, 4610, 9880, 9251, 4111, 13169, 3774, 10685, 4071, 4056, 7164, 3790, 11222, 3815, 3892, 57, 24, 13042, 5595, 3887, 28771, 20, 2]\n",
      "Input tokens: ['▁In', '▁D', 'icks', '▁Welt,', '▁die', '▁der', '▁unseren', '▁ersch', 'reck', 'end', '▁g', 'leicht', ',', '▁schauen', '▁Mut', 'anten', '▁in', '▁die', '▁Zukunft', '▁-', '▁und', '▁die', '▁Polizei', '▁gre', 'ift', '▁zu', '.']\n",
      "Input tensor shape: torch.Size([1, 28])\n",
      "Input indices: [3985, 3866, 12994, 14843, 3827, 3829, 5846, 10892, 13105, 3963, 3845, 7117, 18, 28560, 16412, 8464, 3796, 3827, 6763, 4032, 3830, 3827, 18258, 7456, 7061, 3901, 20, 2]\n",
      "Generated 32 tokens\n",
      "Predicted indices: [1, 4610, 4840, 4071, 3838, 3790, 4840, 4071, 3838, 7995, 14437, 3823, 4170, 3960, 3851, 24183, 4762, 4032, 3838, 17635, 4134, 3796, 3790, 5551, 4032, 3822, 3790, 12510, 3838, 6436, 20, 2]\n",
      "Input tokens: ['▁In', '▁diesem', '▁Jahr', '▁sind', '▁auf', 'reiz', 'ende', '▁unbe', 'leb', 'te', '▁Gegenstände', '▁der', '▁letzte', '▁Sch', 'rei', '.']\n",
      "Input tensor shape: torch.Size([1, 17])\n",
      "Input indices: [3985, 4584, 4422, 4093, 3942, 22076, 5017, 10688, 7099, 3801, 28663, 3829, 11604, 4087, 4699, 20, 2]\n",
      "Generated 17 tokens\n",
      "Predicted indices: [1, 7602, 4484, 4111, 4328, 5695, 3823, 3790, 4950, 3815, 3790, 5430, 5957, 3861, 7177, 14005, 2]\n",
      "Input tokens: ['▁St', 'ile', 'cht', '▁fu', 'hr', '▁er', '▁mit', '▁dem', '▁Z', 'weis', 'p', 'än', 'ner', '▁und', '▁\"Sch', 'war', 'zw', 'äl', 'der', '▁Fü', 'ch', 'sen', '\"', '▁von', '▁Er', 'ich', '▁Be', 'cher', 'er', '▁aus', '▁M', 'ühlen', 'bach', '▁vor', '.']\n",
      "Input tensor shape: torch.Size([1, 36])\n",
      "Input indices: [3989, 4317, 4305, 20239, 3869, 3939, 3952, 3997, 3968, 5339, 86, 4028, 4451, 3830, 9128, 5566, 8568, 4586, 3859, 17102, 3777, 7264, 8, 3923, 4167, 3799, 4121, 6861, 3772, 4048, 3844, 25864, 16863, 4108, 20, 2]\n",
      "Generated 38 tokens\n",
      "Predicted indices: [1, 5115, 4076, 12720, 3908, 4146, 4076, 11921, 3792, 4101, 6385, 5469, 3941, 3790, 8302, 3822, 3804, 3777, 10699, 4141, 5261, 4082, 3800, 13725, 3826, 3822, 3811, 4710, 89, 4082, 3800, 13725, 3826, 3800, 4804, 3916, 20, 2]\n",
      "Input tokens: ['▁Diese', '▁Woche', '▁be', 'zeichnete', '▁die', '▁R', 'ating', '-A', 'gent', 'ur', '▁Standard', '▁&', '▁P', 'oor', \"'s\", '▁wachsende', '▁Haushalts', 'ver', 'schuld', 'ung,', '▁hauptsächlich', '▁durch', '▁steigen', 'de', '▁Hyp', 'othe', 'ken,', '▁als', '▁einen', '▁Risik', 'of', 'akt', 'or', '▁für', '▁die', '▁Kredit', 'würdigkeit', '▁asiat', 'ischer', '▁Bank', 'en.']\n",
      "Input tensor shape: torch.Size([1, 42])\n",
      "Input indices: [6349, 9612, 3836, 13192, 3827, 3883, 4780, 5304, 7913, 3805, 9217, 5707, 3846, 6787, 4231, 24527, 6596, 3940, 16030, 4521, 14374, 4259, 14621, 3912, 24807, 10660, 29262, 3990, 4238, 16414, 6224, 5494, 3788, 3944, 3827, 10659, 17554, 24019, 4992, 6489, 7414, 2]\n",
      "Generated 44 tokens\n",
      "Predicted indices: [1, 7602, 7080, 3790, 3846, 12888, 3814, 29351, 15619, 3900, 3790, 12098, 14155, 3815, 3846, 12888, 3814, 21123, 12793, 11608, 4957, 3790, 7783, 5232, 3815, 27454, 3957, 3774, 7316, 3815, 3774, 7316, 3887, 3790, 9030, 3887, 3790, 9030, 3887, 3790, 19688, 7413, 7685, 2]\n",
      "Input tokens: ['▁Flug', 'reisende', '▁können', '▁jetzt', '▁vom', '▁Ab', 'flug', '▁bis', '▁zur', '▁Land', 'ung', '▁ihre', '▁elektronischen', '▁Geräte', '▁zum', '▁Les', 'en,', '▁Arbeit', 'en,', '▁Spiel', 'en,', '▁Musik', '▁hören', '▁und', '▁dem', '▁An', 'sehen', '▁von', '▁Fil', 'men', '▁verwenden,', '▁nicht', '▁aber', '▁mit', '▁dem', '▁Handy', '▁telefon', 'ieren,', '▁so', '▁die', '▁neuen', '▁Richt', 'lin', 'ien,', '▁die', '▁am', '▁Donnerstag', '▁von', '▁der', '▁Federal', '▁Av', 'iation', '▁Administration', '▁(F', 'A', 'A)', '▁in', '▁den', '▁USA', '▁herausge', 'geben', '▁wurden', '.']\n",
      "Input tensor shape: torch.Size([1, 64])\n",
      "Input indices: [7568, 26714, 4356, 5666, 4724, 4307, 15789, 4541, 4177, 4778, 3821, 4618, 18290, 17417, 4320, 9467, 3855, 4552, 3855, 6146, 3855, 8124, 18241, 3830, 3997, 4038, 10539, 3923, 7193, 4022, 18251, 4012, 4490, 3952, 3997, 22010, 25697, 5499, 3959, 3827, 5369, 5371, 4508, 6077, 3827, 4153, 18730, 3923, 3829, 13829, 13049, 6356, 26099, 8637, 39, 13868, 3796, 3903, 6379, 24549, 5316, 5348, 20, 2]\n",
      "Generated 65 tokens\n",
      "Predicted indices: [1, 6610, 5917, 4148, 4765, 3836, 5354, 3823, 3809, 10505, 4321, 11499, 9708, 3823, 3836, 12550, 3900, 3790, 5721, 3822, 3823, 4686, 3790, 10413, 3988, 4273, 4017, 3941, 3790, 12251, 4439, 4040, 4328, 5500, 3823, 4686, 3790, 4398, 17195, 3900, 3790, 4246, 3815, 3790, 13829, 20498, 3822, 3790, 6265, 4817, 3815, 3790, 13829, 9569, 3815, 13829, 20498, 6489, 89, 3796, 3790, 6265, 4817, 20, 2]\n",
      "Input tokens: ['▁Str', 'ö', 'be', 'le', '▁erklär', 'te,', '▁dass', '▁laut', '▁dem', '▁Anw', 'alt', '▁des', '▁früheren', '▁N', 'SA', '-Mit', 'arbeit', 'ers', '▁Snow', 'den', '▁nicht', '▁nach', '▁Russland', '▁zurück', 'kehren', '▁könn', 'e,', '▁wenn', '▁er', '▁das', '▁Land', '▁ver', 'lass', 'e.']\n",
      "Input tensor shape: torch.Size([1, 35])\n",
      "Input indices: [4904, 216, 4184, 3807, 7686, 4575, 4042, 15543, 3997, 13561, 4519, 3948, 16726, 3956, 16611, 10910, 4548, 3916, 22392, 3886, 4012, 4234, 10016, 5758, 22991, 4911, 3992, 4497, 3939, 3899, 4778, 3938, 5709, 10218, 2]\n",
      "Generated 33 tokens\n",
      "Predicted indices: [1, 3817, 5169, 3790, 3817, 16611, 4076, 4017, 5500, 3823, 7439, 3823, 9618, 13, 3784, 5975, 14550, 4600, 4146, 4937, 3823, 7439, 3823, 9618, 4600, 4146, 3838, 3823, 9761, 3790, 5794, 20, 2]\n",
      "\n",
      "Average BLEU Score over 64 samples: 8.5828\n"
     ]
    }
   ],
   "source": [
    "# Test translation on sample input\n",
    "import torch\n",
    "import sacrebleu\n",
    "\n",
    "@torch.no_grad()\n",
    "def translate_sample(sentence: str, model: TranslationTransformer,\n",
    "                     src_tokenizer: HFTokenizerWrapper, tgt_tokenizer: HFTokenizerWrapper, max_len=100, device=DEVICE):\n",
    "    \"\"\"\n",
    "    Translate a single sentence using the model with autoregressive generation.\n",
    "    \n",
    "    Args:\n",
    "        sentence: Input sentence to translate\n",
    "        model: TranslationTransformer model\n",
    "        src_tokenizer: HFTokenizerWrapper for the source language\n",
    "        tgt_tokenizer: HFTokenizerWrapper for the target language\n",
    "        max_len: Maximum sequence length to generate\n",
    "        device: Device to run on\n",
    "        \n",
    "    Returns:\n",
    "        Translated sentence and token indices\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Tokenize input\n",
    "    src_tokens = src_tokenizer.tokenize(sentence)\n",
    "    print(f\"Input tokens: {src_tokens}\")\n",
    "    \n",
    "    # Encode with EOS token only (source side)\n",
    "    src_indices = src_tokenizer.encode(src_tokens, add_sos=False, add_eos=True)\n",
    "    src_tensor = torch.tensor(src_indices, dtype=torch.long).unsqueeze(0).to(device)  # [1, seq_len]\n",
    "    \n",
    "    # Create source padding mask (all False since no padding in single sentence)\n",
    "    src_key_padding_mask = torch.zeros(1, src_tensor.size(1), dtype=torch.bool).to(device)\n",
    "    \n",
    "    print(f\"Input tensor shape: {src_tensor.shape}\")\n",
    "    print(f\"Input indices: {src_indices}\")\n",
    "    \n",
    "    # Initialize target with just SOS token\n",
    "    tgt_indices = [tgt_tokenizer.sos_idx]\n",
    "    \n",
    "    # Autoregressive generation loop\n",
    "    for _ in range(max_len):\n",
    "        # Convert current target indices to tensor\n",
    "        tgt_tensor = torch.tensor([tgt_indices], dtype=torch.long).to(device)  # [1, current_len]\n",
    "        \n",
    "        # Create target padding mask (all False since we're only generating, no padding)\n",
    "        tgt_key_padding_mask = torch.zeros(1, tgt_tensor.size(1), dtype=torch.bool).to(device)\n",
    "        \n",
    "        # Forward pass with masks\n",
    "        output = model(src_tensor, tgt_tensor, \n",
    "                      src_key_padding_mask=src_key_padding_mask,\n",
    "                      tgt_key_padding_mask=tgt_key_padding_mask)  # [1, current_len, vocab_size]\n",
    "        \n",
    "        # Get prediction for the last token\n",
    "        next_token_logits = output[0, -1, :]  # [vocab_size]\n",
    "        next_token = torch.argmax(next_token_logits).item()\n",
    "        \n",
    "        # Append predicted token\n",
    "        tgt_indices.append(next_token)\n",
    "        \n",
    "        # Stop if we predict EOS token\n",
    "        if next_token == tgt_tokenizer.eos_idx:\n",
    "            break\n",
    "    \n",
    "    print(f\"Generated {len(tgt_indices)} tokens\")\n",
    "    print(f\"Predicted indices: {tgt_indices}\")\n",
    "    \n",
    "    # Decode back to tokens (skip SOS and EOS)\n",
    "    translation = tgt_tokenizer.decode_to_text(tgt_indices)  # Remove SOS and EOS\n",
    "        \n",
    "    return translation, tgt_indices\n",
    "\n",
    "# Test with a sample German sentence from the dataset\n",
    "total_bleu = 0.0\n",
    "print_enabled = False\n",
    "\n",
    "batch_de, batch_en, _, _ = next(iter(test_loader))\n",
    "samples = len(batch_de)\n",
    "\n",
    "for idx, (de, en) in enumerate(zip(batch_de, batch_en)):\n",
    "    sample_de = tokenizer.decode_to_text(de.tolist())\n",
    "    sample_en = tokenizer.decode_to_text(en.tolist())\n",
    "\n",
    "    translation, _ = translate_sample(\n",
    "        sample_de, \n",
    "        model, \n",
    "        src_tokenizer=tokenizer,\n",
    "        tgt_tokenizer=tokenizer,\n",
    "        max_len=max_len,\n",
    "        device=DEVICE\n",
    "    )\n",
    "    BLEUscore = sacrebleu.corpus_bleu([translation], [[sample_en]])\n",
    "    total_bleu += BLEUscore.score\n",
    "\n",
    "    if print_enabled:\n",
    "        print(f\"Original German: {sample_de}\")\n",
    "        print(f\"Original English: {sample_en}\")\n",
    "        print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(f\"\\nModel Translation: '{translation}'\")\n",
    "        print(f\"Reference Translation: {sample_en}\")\n",
    "        print(f\"BLEU Score: {BLEUscore.score:.4f}\")\n",
    "\n",
    "print(f\"\\nAverage BLEU Score over {samples} samples: {(total_bleu / samples):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64c2986e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tokens: ['▁Gut', 'ach', ':', '▁Noch', '▁mehr', '▁Sicherheit', '▁für', '▁Fuß', 'gänger']\n",
      "Input tensor shape: torch.Size([1, 10])\n",
      "Input indices: [15332, 3922, 32, 27488, 4479, 5427, 3944, 8804, 18100, 2]\n",
      "Generated 13 tokens\n",
      "Predicted indices: [1, 7418, 7429, 4323, 6114, 3838, 5397, 3774, 5879, 3887, 18864, 20, 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'And yet more security is still a matter for football.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "translation, _ = translate_sample(\n",
    "    tokenizer.decode_to_text(test_ds[0][0].tolist()),\n",
    "    model, \n",
    "    src_tokenizer=tokenizer,\n",
    "    tgt_tokenizer=tokenizer,\n",
    "    max_len=max_len,\n",
    "    device=DEVICE\n",
    ")\n",
    "translation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b025d4",
   "metadata": {},
   "source": [
    "\n",
    "## Saving and loading the model\n",
    "\n",
    "To load the model later, use:\n",
    "```python\n",
    "checkpoint = torch.load('./models/translation_model.pt')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
